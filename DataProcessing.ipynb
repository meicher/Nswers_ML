{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4f6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1cf7c",
   "metadata": {},
   "source": [
    "## 1.2 Students "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2821b470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22541, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read file, drop dupes that occur across all columns, and then drop the 54 duplicates that are dupes at the ID level (22595-> 22541)\n",
    "stu = pd.read_csv('files/1.2 Students.csv',parse_dates=['HighSchoolGraduationDate','BirthDate'])\n",
    "stu.drop_duplicates(inplace=True)\n",
    "stu = stu[stu.duplicated('nswersguid')==0]\n",
    "\n",
    "#create grouped language indicator field (english / spanish / other)  - other values aren't frequent\n",
    "stu['lang'] = np.where((stu['HomeLanguageCode']!= 'English') & (stu['HomeLanguageCode']!= 'Spanish'),\n",
    "         'Other languages',\n",
    "         stu['HomeLanguageCode'])\n",
    "\n",
    "#Drop missing data columns (almost or all missing)\n",
    "stu.drop(['Race2','Race3','Race4','Race5','ImmigrantIndicator'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# create hs grad indicator, and on-time indicator\n",
    "stu['HS_Grad'] = np.where(stu['HighSchoolGraduationDate'].isnull(),0,1)\n",
    "stu['HS_Grad_ontime']  =  np.where(stu['HighSchoolGraduationDate']<'2012',1,0)\n",
    "\n",
    "#create target var\n",
    "target1=stu['HS_Grad']\n",
    "target2=stu['HS_Grad_ontime']\n",
    "\n",
    "#could create stu[age] from bdate -> 2011\n",
    "stu['age']  =(pd.to_datetime('2011') - stu['BirthDate']) / np.timedelta64(1, 'Y')\n",
    "\n",
    "#get part1 of district number\n",
    "stu['DistrictNumber1'] = stu['DistrictNumber'].str.split('-').str[0]\n",
    "\n",
    "\n",
    "#drop vars not useful or only used in transform above\n",
    "stu.drop(['HighSchoolGraduationDate','GradeLevel','HomeLanguageCode',\n",
    "          'School_Year','SchoolName','BirthDate','DistrictNumber'],\n",
    "         axis=1,inplace=True)\n",
    "\n",
    "#get dummies\n",
    "\n",
    "#first set of features from 1.2 \n",
    "features = stu.drop(['HS_Grad','HS_Grad_ontime','nswersguid'],axis=1)\n",
    "features[['Gender','Race1','lang','DistrictNumber1','SchoolNumber']] = features[features.columns[features.dtypes == 'O']].astype('category')\n",
    "\n",
    "#featuresdum = pd.get_dummies(stu.drop(['HS_Grad','HS_Grad_ontime','nswersguid','DistrictNumber1'],axis=1))\n",
    "#featuresdum_dropfirst = pd.get_dummies(stu.drop(['HS_Grad','HS_Grad_ontime','nswersguid'],axis=1),drop_first=True)\n",
    "\n",
    "stu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ada761",
   "metadata": {},
   "source": [
    "## 1.4 Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da92d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274601, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1.4 Grades\n",
    "grades = pd.read_csv('files/1.4 Student Grades.csv')\n",
    "\n",
    "# dropping dist/school number - info captured in 1.2\n",
    "#dropping school year/grade level - info low variance, and possibly represents data leakage for prediction\n",
    "#dropping dual credit - only 16 'yes' values\n",
    "grades.drop(['DistrictNumber','SchoolNumber','DualCreditIndicator','School Year','GradeLevel'],axis=1,inplace=True)\n",
    "grades['AlphaGrade'] = grades['AlphaGrade'].fillna('NA')\n",
    "grades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44712d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nswersguid           0.000000\n",
       "Evaluator1StaffId    0.162337\n",
       "AlphaGrade           0.000000\n",
       "Term                 0.008092\n",
       "CourseCode           0.008092\n",
       "SectionCode          0.008092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#408 unique course codes (state course code)\n",
    "#50k unique section codes\n",
    "#7133 unique evaluators\n",
    "#17 unique term types\n",
    "grades.isnull().sum() / len(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14652b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique counts by student\n",
    "unique = grades.groupby('nswersguid').nunique().reset_index().rename(columns={'Evaluator1StaffId':'UniqueTeachers',\n",
    "                                                                    'CourseCode':'UniqueCourseCodes',\n",
    "                                                                    'SectionCode':'UniqueSectionCodes',\n",
    "                                                                    'AlphaGrade':'UniqueAlphaGrades',\n",
    "                                                                    'Term':'UniqueTerms'})\n",
    "\n",
    "#pivot grades for individual grade counts per student\n",
    "alphas= pd.pivot_table(grades[['nswersguid','AlphaGrade','CourseCode']],\n",
    "               index=['nswersguid'],columns=['AlphaGrade'],aggfunc='count',dropna=False,fill_value=0).reset_index(col_level=1)\n",
    "alphas.columns = alphas.columns.droplevel()\n",
    "alphas.drop(['nswersguid'],axis=1,inplace=True)\n",
    "\n",
    "#total course count, could be useful to show retakes\n",
    "totalcourses = grades.groupby('nswersguid').count().reset_index().rename(columns={\n",
    "                                                                    'SectionCode':'TotalSectionCodes'\n",
    "                                                                })[['TotalSectionCodes']]\n",
    "#concatenate the 3 sets of grades features on the index\n",
    "courses = pd.concat([totalcourses,unique,alphas],axis=1)\n",
    "courses['retakeCount']= courses['TotalSectionCodes'] - courses['UniqueSectionCodes']\n",
    "courses = courses.add_prefix('grd_')\n",
    "\n",
    "#max / min grades\n",
    "# relative grades to district average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1656f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add courses to original student file\n",
    "stu = stu.merge(courses,left_on='nswersguid',right_on='grd_nswersguid').drop('grd_nswersguid',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03a738",
   "metadata": {},
   "source": [
    "## 1.5 NESA State Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9896fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22541, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1.5 NESA State Assessment\n",
    "nesa = pd.read_csv('files/1.5 NeSA State Assessment.csv')\n",
    "\n",
    "#drop redundant columns, and drop rows where no NESA Assessment (after adding missing indicator)\n",
    "nesa.drop(['DistrictNumber','SchoolNumber','School Year','GradeLevel','Subject'],axis=1,inplace=True)\n",
    "nesa = nesa.add_prefix('nesa_')\n",
    "nesa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead5513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stu = stu.merge(nesa,left_on='nswersguid',right_on='nesa_nswersguid').drop('nesa_nswersguid',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8527cc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#these need to be after train/test split, otherwise probably biasing the results of prediction\n",
    "#     along with any other calculated fields that ARE NOT calc'd at student level\n",
    "\n",
    "#add difference between district avg scalescore and student scale score\n",
    "stu['DistrictStudent_ScaleScore_Diff'] = stu.groupby('DistrictNumber1')['nesa_ScaleScore'].transform('mean') - stu['nesa_ScaleScore']\n",
    "\n",
    "#add difference between school avg scalescore and student scale score\n",
    "stu['SchoolStudent_ScaleScore_Diff'] = stu.groupby('SchoolNumber')['nesa_ScaleScore'].transform('mean') - stu['nesa_ScaleScore']\n",
    "\n",
    "#courses differences between student / district / school\n",
    "#grd_A, grd_B, etc as % of total course grades earned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442dcf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export HIGH SCHOOL level data -- for use in predictions of College Going Rate + HS Grad Rate + HS Ontime rate\n",
    "stu.to_csv('Students_HS_v1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
